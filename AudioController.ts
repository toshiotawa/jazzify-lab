/**
 * AudioController.ts - é«˜åº¦ãªãƒ”ãƒƒãƒæ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ 
 * WASMçµ±åˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³éŸ¿å‡¦ç†ã€HMMã«ã‚ˆã‚‹éŸ³ç¬¦å®‰å®šåŒ–ã‚’å®Ÿè£…
 */

import init, { 
    analyze_pitch, 
    alloc, 
    free, 
    get_memory,
    init_pitch_detector,
    get_ring_buffer_ptr,
    get_ring_buffer_size,
    process_audio_block
} from './src/wasm/pitch_detector.js';

import type { 
  AudioControllerOptions, 
  SpectralPeak, 
  SpectralAnalysis, 
  PitchResult,
  PitchCandidate,
  PitchHistory,
  AudioProcessingSettings,
  WASMModule
} from './src/types';

// WASMå¤–éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ–
let wasmMemory: WebAssembly.Memory | null = null;
let wasmInstance: any = null;

// iOSæ¤œå‡ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
const isIOS = (): boolean => {
  return /iPad|iPhone|iPod/.test(navigator.userAgent) && !('MSStream' in window);
};

/**
 * éš ã‚Œãƒãƒ«ã‚³ãƒ•ãƒ¢ãƒ‡ãƒ«ï¼ˆHMMï¼‰ãƒ—ãƒ­ã‚»ãƒƒã‚µ
 * ãƒ”ãƒƒãƒæ¤œå‡ºã®å®‰å®šæ€§å‘ä¸Šã®ãŸã‚çŠ¶æ…‹é·ç§»ã‚’ç®¡ç†
 */
class HMMProcessor {
  private readonly minNote: number;
  private readonly maxNote: number;
  private readonly numStates: number;
  private readonly currentStateProbs: Float32Array;
  private readonly transitionMatrix: Float32Array;

  constructor(minNote: number = 21, maxNote: number = 108) {
    this.minNote = minNote;
    this.maxNote = maxNote;
    this.numStates = maxNote - minNote + 1;
    this.currentStateProbs = new Float32Array(this.numStates);
    this.transitionMatrix = new Float32Array(this.numStates * this.numStates);
    
    // åˆæœŸåŒ–: å‡ç­‰åˆ†å¸ƒ
    this.currentStateProbs.fill(1 / this.numStates);
    this.calculateTransitionProbabilities();
  }

  private calculateTransitionProbabilities(): void {
    const sameNoteProb = 0.6;
    const stepProb = 0.3;

    for (let i = 0; i < this.numStates; i++) {
      // åŒä¸€éŸ³ç¶­æŒ
      this.transitionMatrix[i * this.numStates + i] = sameNoteProb;
      
      // åŠéŸ³ï½2å…¨éŸ³ç¨‹åº¦ã®ç§»å‹•
      for (let j = Math.max(0, i-4); j <= Math.min(this.numStates-1, i+4); j++) {
        if (j !== i) {
          this.transitionMatrix[i * this.numStates + j] = stepProb / 8;
        }
      }
      
      // å¤§ããªè·³èº
      const remainingProb = 1 - (sameNoteProb + stepProb);
      const largeJumpNotes = this.numStates - 9;
      if (largeJumpNotes > 0) {
        for (let j = 0; j < this.numStates; j++) {
          if (Math.abs(i - j) > 4) {
            this.transitionMatrix[i * this.numStates + j] += remainingProb / largeJumpNotes;
          }
        }
      }
    }
  }

  public update(observations: Float32Array): void {
    const newProbs = new Float32Array(this.numStates);
    
    for (let j = 0; j < this.numStates; j++) {
      let sum = 0;
      for (let i = 0; i < this.numStates; i++) {
        sum += this.currentStateProbs[i] * this.transitionMatrix[i * this.numStates + j];
      }
      newProbs[j] = sum * observations[j];
    }
    
    // æ­£è¦åŒ–
    const total = newProbs.reduce((a, b) => a + b, 0);
    if (total > 0) {
      for (let i = 0; i < this.numStates; i++) {
        this.currentStateProbs[i] = newProbs[i] / total;
      }
    }
  }

  public getMostProbableNote(): number {
    let maxProb = 0;
    let bestNote = -1;
    
    for (let i = 0; i < this.numStates; i++) {
      if (this.currentStateProbs[i] > maxProb) {
        maxProb = this.currentStateProbs[i];
        bestNote = this.minNote + i;
      }
    }
    
    return bestNote;
  }
}

/**
 * ãƒ¡ã‚¤ãƒ³ã®AudioControllerã‚¯ãƒ©ã‚¹
 * WASMçµ±åˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³éŸ¿å‡¦ç†ã€ãƒ”ãƒƒãƒæ¤œå‡ºã‚’çµ±åˆç®¡ç†
 */
export class AudioController {
  // ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
  private readonly onNoteOn: (note: number, velocity?: number) => void;
  private readonly onNoteOff: (note: number) => void;
  private onConnectionChange: ((connected: boolean) => void) | null = null;

  // Web Audio API
  private audioContext: AudioContext | null = null;
  private mediaStream: MediaStream | null = null;
  private workletNode: AudioWorkletNode | null = null;
  private scriptNode: ScriptProcessorNode | null = null;
  private analyserNode: AnalyserNode | null = null;
  private analyserTimer: number | null = null;

  // ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†
  private currentDeviceId: string | null = null;
  private readonly errorDisplays = new Map<string, Element>();

  // å‡¦ç†çŠ¶æ…‹
  private isProcessing: boolean = false;
  private pauseProcessing: boolean = false;
  private readonly isIOSDevice: boolean;
  private activeNote: number | null = null;

  // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  private sampleRate: number | null = null;
  private readonly processingSettings: AudioProcessingSettings;

  // ãƒãƒƒãƒ•ã‚¡ç®¡ç†
  private readonly samples: Float32Array;
  private readonly lowFreqSamples: Float32Array;
  private accumulatedSamples: Float32Array = new Float32Array(0);
  private readonly pitchHistory: PitchHistory[] = [];
  private readonly pitchHistorySize: number = 3;
  private pitchProbabilityBuffer: Float32Array[] = [];

  // ãƒãƒ¼ãƒˆçŠ¶æ…‹
  private lastDetectedNote: number = -1;
  private consecutiveFrames: number = 0;
  private lastStableNote: number = -1;
  private currentNote: number = -1;
  private lastNoteOnTime: number = 0;
  private lastDetectedFrequency: number = 0;
  private isNoteOn: boolean = false;
  private lastPitchConfidence: number = 0.0;

  // WASMçµ±åˆ
  private ringBufferPtr: number = 0;
  private ringSize: number = 0;
  private writeIndex: number = 0;

  // å‘¨æ³¢æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã¨HMM
  private readonly noteFrequencies = new Map<number, number>();
  private readonly hmmProcessor: HMMProcessor;

  // ã‚­ãƒ¼ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆMIDIControllerçµ±åˆç”¨ï¼‰
  private keyHighlightCallback: ((note: number, active: boolean) => void) | null = null;
  
  // PIXIãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆGameEngineçµ±åˆç”¨ï¼‰
  private keyPressEffectCallback: ((note: number) => void) | null = null;

  private outputGainNode: GainNode | null = null;

  constructor(options: AudioControllerOptions) {
    console.log('[AudioController] Constructor called');
    
    this.onNoteOn = options.onNoteOn;
    this.onNoteOff = options.onNoteOff;
    this.onConnectionChange = options.onConnectionChange || null;

    // å‡¦ç†è¨­å®šã®åˆæœŸåŒ–
    this.processingSettings = {
      bufferSize: 512,
      lowFreqBufferSize: 1024,
      minFrequency: 27.5,
      maxFrequency: 4186.01,
      amplitudeThreshold: 0.1,
      consecutiveFramesThreshold: 1,
      noteOnThreshold: 0.05,
      noteOffThreshold: 0.03,
      maxAllowedPitchChange: 1.5,
      lowFrequencyThreshold: 200.0,
      lowFrequencyAmplitudeThreshold: 0.08,
      veryLowFreqThreshold: 100.0,
      pyinThreshold: 0.1,
      silenceThreshold: 0.01,
      adaptiveBuffering: true,
    };

    // ãƒãƒƒãƒ•ã‚¡åˆæœŸåŒ–
    this.samples = new Float32Array(this.processingSettings.bufferSize);
    this.lowFreqSamples = new Float32Array(this.processingSettings.lowFreqBufferSize);

    // ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æ¤œå‡º
    this.isIOSDevice = isIOS();
    if (this.isIOSDevice) {
      console.log('iOSç’°å¢ƒã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚ç‰¹åˆ¥ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡¦ç†ã‚’é©ç”¨ã—ã¾ã™ã€‚');
    }

    // ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    this.initializeNoteFrequencies();
    this.hmmProcessor = new HMMProcessor();
    
    // WASMåˆæœŸåŒ–ã‚’éåŒæœŸã§å®Ÿè¡Œ
    this.initializeWASM().catch((error) => {
      console.error('Failed to initialize WASM:', error);
    });
  }

  /**
   * WASM ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–
   */
  private async initializeWASM(): Promise<void> {
    try {
      console.log("WASM ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–ã‚’é–‹å§‹");
      wasmInstance = await init();
      wasmMemory = get_memory();
      console.log("WASM ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ");
    } catch (error) {
      console.error('WASM initialization failed:', error);
      throw error;
    }
  }

  /**
   * å‘¨æ³¢æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆæœŸåŒ–ï¼ˆA0ã‹ã‚‰C8ã¾ã§ - 88éµç›¤å…¨ä½“ï¼‰
   */
  private initializeNoteFrequencies(): void {
    for (let i = 21; i <= 108; i++) {
      const frequency = 440 * Math.pow(2, (i - 69) / 12);
      this.noteFrequencies.set(i, frequency);
    }
  }

  /**
   * ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ã«æ¥ç¶š
   */
  public async connectDevice(deviceId: string): Promise<boolean> {
    try {
      console.log('ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹æ¥ç¶šã‚’é–‹å§‹:', deviceId);
      
      // æ—¢å­˜ã®æ¥ç¶šã‚’åˆ‡æ–­ (ãŸã ã—iOSã§ã¯AudioContextã¯ä¿æŒ)
      if (this.mediaStream) {
        this.mediaStream.getTracks().forEach(track => {
          console.log('æ—¢å­˜ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒˆãƒ©ãƒƒã‚¯ã‚’åœæ­¢:', track.kind, track.label);
          track.stop();
        });
        this.mediaStream = null;
      }
      
      // getUserMedia ã®å­˜åœ¨ç¢ºèª
      if (!navigator.mediaDevices || typeof navigator.mediaDevices.getUserMedia !== 'function') {
        console.warn('navigator.mediaDevices.getUserMedia is not supported in this environment.');
        this.showError('Microphone access is not supported.');
        this.notifyConnectionChange(false);
        return false;
      }

      // ãƒ‡ãƒã‚¤ã‚¹ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’å–å¾—
      console.log('ãƒã‚¤ã‚¯è¨±å¯ã‚’è¦æ±‚...');
      try {
        this.mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            deviceId: deviceId ? { exact: deviceId } : undefined,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          },
          video: false
        });
        console.log('ãƒã‚¤ã‚¯è¨±å¯ã‚’å–å¾—ã—ã¾ã—ãŸ:', 
          this.mediaStream.getAudioTracks().map(t => t.label).join(', '));
      } catch (getUserMediaError) {
        console.error('[AudioController] getUserMedia failed:', getUserMediaError);
        this.showError(`Failed to access microphone: ${(getUserMediaError as Error).message}`);
        this.notifyConnectionChange(false);
        return false;
      }

      // AudioContextã®ä½œæˆã¾ãŸã¯å†åˆ©ç”¨
      let needNewContext = true;
      if (this.isIOSDevice && this.audioContext) {
        if (this.audioContext.state === 'suspended') {
          try {
            console.log('iOS: æ—¢å­˜ã®AudioContextã‚’å†é–‹ã—ã¾ã™');
            await this.audioContext.resume();
            needNewContext = false;
          } catch (e) {
            console.warn('æ—¢å­˜ã®AudioContextã®å†é–‹ã«å¤±æ•—ã—ã¾ã—ãŸ:', e);
            needNewContext = true;
          }
        } else if (this.audioContext.state === 'running') {
          console.log('iOS: æ—¢å­˜ã®AudioContextã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™');
          needNewContext = false;
        }
      }

      if (needNewContext || !this.audioContext) {
        if (this.audioContext && !this.isIOSDevice) {
          console.log('æ—¢å­˜ã®AudioContextã‚’é–‰ã˜ã¾ã™');
          await this.audioContext.close();
        }
        console.log('æ–°ã—ã„AudioContextã‚’ä½œæˆã—ã¾ã™');
        this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        this.sampleRate = this.audioContext.sampleRate;
        console.log('[AudioController] New AudioContext created. State:', this.audioContext.state, 'Sample Rate:', this.sampleRate);
      } else {
        this.sampleRate = this.audioContext.sampleRate;
        console.log('[AudioController] Using existing AudioContext. State:', this.audioContext.state, 'Sample Rate:', this.sampleRate);
      }

      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚½ãƒ¼ã‚¹ã®ä½œæˆ
      const source = this.audioContext.createMediaStreamSource(this.mediaStream);
      console.log('MediaStreamSourceã‚’ä½œæˆã—ã¾ã—ãŸ');

      // ãƒ–ãƒ©ã‚¦ã‚¶ã«å¿œã˜ãŸå‡¦ç†ã‚’é¸æŠ
      if (window.AudioWorkletNode) {
        console.log('AudioWorkletã‚’ä½¿ç”¨ã—ã¾ã™');
        await this.setupAudioWorklet(source);
      } else {
        console.log('ScriptProcessorNodeã‚’ä½¿ç”¨ã—ã¾ã™');
        this.createScriptProcessorFallback(source);
      }

      // ç¾åœ¨ã®ãƒ‡ãƒã‚¤ã‚¹IDã‚’è¨˜éŒ²
      const tracks = this.mediaStream.getAudioTracks();
      if (tracks.length > 0) {
        const settings = tracks[0].getSettings();
        this.currentDeviceId = settings.deviceId || deviceId;
        
        // ã™ã¹ã¦ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹é¸æŠãƒªã‚¹ãƒˆã‚’åŒæœŸ
        document.querySelectorAll('.audio-devices').forEach(select => {
          (select as HTMLSelectElement).value = this.currentDeviceId || '';
        });
        console.log('ãƒ‡ãƒã‚¤ã‚¹ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’åŒæœŸã—ã¾ã—ãŸ');
      }

      this.notifyConnectionChange(true);
      this.hideError();
      console.log('ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹æ¥ç¶šå®Œäº†:', deviceId);
      
      // ãƒ‡ãƒã‚¤ã‚¹ãƒªã‚¹ãƒˆã‚’æ›´æ–°
      await this.updateDeviceList();
      
      return true;
    } catch (error) {
      console.error('ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼:', error);
      this.showError('Failed to connect to audio device. Please ensure microphone permissions are granted.');
      return false;
    }
  }

  /**
   * AudioWorkletã®è¨­å®š
   */
  private async setupAudioWorklet(source: MediaStreamAudioSourceNode): Promise<void> {
    try {
      console.log('Setting up AudioWorklet, sample rate:', this.audioContext!.sampleRate);
      
      // Wait for WASM to be ready
      if (!wasmMemory) {
        console.log('Waiting for WASM to initialize...');
        await new Promise<void>(resolve => {
          const checkWasm = () => {
            if (wasmMemory) {
              resolve();
            } else {
              setTimeout(checkWasm, 10);
            }
          };
          checkWasm();
        });
      }
      
      // Initialize WASM pitch detector with sample rate
      console.log('Initializing WASM pitch detector');
      init_pitch_detector(this.audioContext!.sampleRate);
      
      await this.audioContext!.audioWorklet.addModule('/js/audio/audio-worklet-processor.js');
      this.workletNode = new AudioWorkletNode(this.audioContext!, 'audio-processor');
      
      // Get ring buffer pointer and size from WASM
      const ringBufferPtr = get_ring_buffer_ptr();
      const ringSize = get_ring_buffer_size();
      
      console.log('Ring buffer ptr:', ringBufferPtr, 'size:', ringSize);
      
      // Store reference for WorkletNode to access WASM memory
      this.ringBufferPtr = ringBufferPtr;
      this.ringSize = ringSize;
      this.writeIndex = 0;
      
      // Initialize AudioWorklet with ring buffer info (without memory object)
      this.workletNode.port.postMessage({
        type: 'init',
        ptr: ringBufferPtr,
        ringSize: ringSize
      });
      
      // Create or reuse GainNode for smooth volume ramp
      if (!this.outputGainNode) {
        this.outputGainNode = this.audioContext!.createGain();
        this.outputGainNode.gain.value = 0; // start muted
      }

      this.workletNode.port.onmessage = (e) => {
        console.log('Received message from AudioWorklet:', e.data.type);
        if (e.data.type === 'samples') {
          // Process samples with new low-latency method
          this.processLowLatencySamples(e.data.samples);
        } else if (e.data.samples) {
          // Fallback to old method if needed
          console.log('Using fallback processAudioData');
          this.processAudioData(e.data.samples);
        } else {
          console.log('Unknown message type:', e.data);
        }
      };
      
      source.connect(this.workletNode);
      this.workletNode.connect(this.outputGainNode);
      this.outputGainNode.connect(this.audioContext!.destination);
      this.fadeInOutput();
      this.isProcessing = true;
      console.log('AudioWorkletNodeè¨­å®šå®Œäº† (ãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡ãƒ¢ãƒ¼ãƒ‰)');
    } catch (workletError) {
      console.warn('AudioWorkletåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã€ScriptProcessorã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯:', workletError);
      this.createScriptProcessorFallback(source);
    }
  }

  /**
   * ScriptProcessorãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
   */
  private createScriptProcessorFallback(source: MediaStreamAudioSourceNode): void {
    // audioContextãŒnullã®å ´åˆã¯å†ä½œæˆ
    if (!this.audioContext) {
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      this.audioContext = new AudioContextClass();
      
      if (this.audioContext.state !== 'running') {
        this.audioContext.resume();
      }
      
      this.sampleRate = this.audioContext.sampleRate;
      // sourceã‚‚å†ä½œæˆãŒå¿…è¦
      if (this.mediaStream) {
        source = this.audioContext.createMediaStreamSource(this.mediaStream);
      } else {
        console.error('ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“');
        throw new Error('ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“');
      }
    }

    // ä¸€éƒ¨ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯createScriptProcessorãŒéæ¨å¥¨ã¾ãŸã¯åˆ©ç”¨ä¸å¯
    if (typeof this.audioContext.createScriptProcessor !== 'function') {
      console.warn('ScriptProcessorNodeãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AnalyserNodeãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™');
      // AnalyserNodeã‚’ä½¿ã£ãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      this.analyserNode = this.audioContext.createAnalyser();
      this.analyserNode.fftSize = this.processingSettings.bufferSize * 2;
      source.connect(this.analyserNode);
      
      // ãƒ‡ãƒ¼ã‚¿å–å¾—ç”¨ã®ã‚¿ã‚¤ãƒãƒ¼ã‚’è¨­å®š
      this.analyserTimer = window.setInterval(() => {
        const dataArray = new Float32Array(this.processingSettings.bufferSize);
        this.analyserNode!.getFloatTimeDomainData(dataArray);
        this.processAudioData(dataArray);
      }, 100); // 100msã”ã¨ã«å‡¦ç†
      
      return;
    }

    this.scriptNode = this.audioContext.createScriptProcessor(
      this.processingSettings.bufferSize,
      1,
      1
    );
    this.scriptNode.onaudioprocess = (e) => {
      const inputData = e.inputBuffer.getChannelData(0);
      this.processAudioData(inputData);
    };
    source.connect(this.scriptNode);

    // Create or reuse GainNode
    if (!this.outputGainNode) {
      this.outputGainNode = this.audioContext!.createGain();
      this.outputGainNode.gain.value = 0;
    }

    this.scriptNode.connect(this.outputGainNode);
    this.outputGainNode.connect(this.audioContext!.destination);
    this.fadeInOutput();
    console.log('ScriptProcessorNodeè¨­å®šå®Œäº†');
  }

  /**
   * ä½é…å»¶ã‚µãƒ³ãƒ—ãƒ«å‡¦ç†ï¼ˆWASMçµ±åˆï¼‰
   */
  private processLowLatencySamples(samples: Float32Array): void {
    if (this.pauseProcessing) {
      return;
    }
    
    if (!wasmMemory || !wasmInstance) {
      this.processAudioData(samples);
      return;
    }
    
    if (!this.ringBufferPtr || !this.ringSize) {
      this.processAudioData(samples);
      return;
    }
    
    const currentMemory = get_memory();
    const requiredBytes = this.ringBufferPtr + (this.ringSize * 4);
    if (requiredBytes > currentMemory.buffer.byteLength) {
      console.error('Ring buffer pointer out of bounds!');
      this.processAudioData(samples);
      return;
    }
    
    const ringBuffer = new Float32Array(currentMemory.buffer, this.ringBufferPtr, this.ringSize);
    
    // ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡ã«ã‚³ãƒ”ãƒ¼
    for (let i = 0; i < samples.length; i++) {
      ringBuffer[this.writeIndex] = samples[i];
      this.writeIndex = (this.writeIndex + 1) % this.ringSize;
    }
    
    // 32ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«å‡¦ç†ï¼ˆè¶…ä½é…å»¶ï¼‰
    if ((this.writeIndex & 0x1F) === 0) {
      const frequency = process_audio_block(this.writeIndex);
      
      if (frequency > 0 && frequency >= this.processingSettings.minFrequency && frequency <= this.processingSettings.maxFrequency) {
        this.handleDetectedPitch(frequency);
      } else {
        this.handleNoPitch();
      }
    }
  }

  /**
   * åŸºæœ¬éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†
   */
  private processAudioData(inputData: Float32Array): void {
    if (!this.isProcessing) return;

    // ç´¯ç©ãƒãƒƒãƒ•ã‚¡ã«ä»Šå›ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¿½åŠ 
    if (!this.accumulatedSamples) {
      this.accumulatedSamples = new Float32Array(0);
    }
    const newBuffer = new Float32Array(this.accumulatedSamples.length + inputData.length);
    newBuffer.set(this.accumulatedSamples);
    newBuffer.set(inputData, this.accumulatedSamples.length);
    this.accumulatedSamples = newBuffer;

    // ç´¯ç©ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒ bufferSize ä»¥ä¸Šã«ãªã£ãŸã‚‰ãƒ–ãƒ­ãƒƒã‚¯æ¯ã«å‡¦ç†
    while (this.accumulatedSamples.length >= this.processingSettings.bufferSize) {
      // å…ˆé ­ bufferSize ã‚µãƒ³ãƒ—ãƒ«ã‚’åˆ‡ã‚Šå‡ºã™
      const block = this.accumulatedSamples.subarray(0, this.processingSettings.bufferSize);
      this.processBlock(block);

      // ãƒ—ãƒ­ã‚»ã‚¹æ¸ˆã¿ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’é™¤å»
      const remaining = new Float32Array(this.accumulatedSamples.length - this.processingSettings.bufferSize);
      remaining.set(this.accumulatedSamples.subarray(this.processingSettings.bufferSize));
      this.accumulatedSamples = remaining;
    }
    
    // Adaptive buffering for low frequencies
    if (this.processingSettings.adaptiveBuffering && this.accumulatedSamples.length >= this.processingSettings.lowFreqBufferSize) {
      // Check if we might be dealing with low frequencies
      const preliminaryBlock = this.accumulatedSamples.subarray(0, this.processingSettings.bufferSize);
      const maxAmplitude = this.calculateMaxAmplitude(preliminaryBlock);
      
      if (maxAmplitude > this.processingSettings.noteOnThreshold) {
        // Perform a quick spectral analysis to check if low frequency content is present
        const spectral = this.analyzeSpectralContent(preliminaryBlock);
        if (spectral.centroid < this.processingSettings.veryLowFreqThreshold) {
          // Use larger buffer for low frequency detection
          const largeBlock = this.accumulatedSamples.subarray(0, this.processingSettings.lowFreqBufferSize);
          this.processLowFreqBlock(largeBlock);
          
          // Remove processed samples
          const remaining = new Float32Array(this.accumulatedSamples.length - this.processingSettings.lowFreqBufferSize);
          remaining.set(this.accumulatedSamples.subarray(this.processingSettings.lowFreqBufferSize));
          this.accumulatedSamples = remaining;
        }
      }
    }
  }

  private processLowFreqBlock(block: Float32Array): void {
    // Process low frequency content with larger buffer
    this.lowFreqSamples.set(block);
    
    // Calculate maximum amplitude
    const maxAmplitude = this.calculateMaxAmplitude(this.lowFreqSamples);
    
    // Update note state
    this.updateNoteState(maxAmplitude);
    
    if (!this.isNoteOn) {
      this.resetDetection();
      return;
    }
    
    // Analyze with larger buffer for better low frequency resolution
    const spectral = this.analyzeSpectralContent(this.lowFreqSamples);
    const pitchResult = this.analyzePitchLowFreq(this.lowFreqSamples, spectral);
    const frequency = pitchResult.frequency;
    const confidence = pitchResult.confidence;
    const observationProbs = pitchResult.observationProbs;
    
    // Record confidence
    this.lastPitchConfidence = confidence;
    
    this.processDetectedFrequency(frequency, observationProbs, confidence);
  }

  private processBlock(block: Float32Array): void {
    // ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã¯this.bufferSize ã®é•·ã•ã«ãªã£ã¦ã„ã‚‹å‰æ
    this.samples.set(block);

    // æœ€å¤§æŒ¯å¹…ã‚’è¨ˆç®—ï¼ˆæœ€é©åŒ–ã‚³ãƒ¼ãƒ‰ã¯ãã®ã¾ã¾ï¼‰
    let maxAmplitude = 0;
    let i = 0;
    const bufferSize = this.processingSettings.bufferSize;
    for (; i < bufferSize - 3; i += 4) {
      maxAmplitude = Math.max(maxAmplitude, 
        Math.max(
          Math.max(Math.abs(this.samples[i]), Math.abs(this.samples[i + 1])),
          Math.max(Math.abs(this.samples[i + 2]), Math.abs(this.samples[i + 3]))
        )
      );
    }
    for (; i < bufferSize; i++) {
      maxAmplitude = Math.max(maxAmplitude, Math.abs(this.samples[i]));
    }
    
    // ãƒãƒ¼ãƒˆã®çŠ¶æ…‹ã‚’æ›´æ–°
    this.updateNoteState(maxAmplitude);

    if (!this.isNoteOn) {
      this.resetDetection();
      return;
    }

    // PYINã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§å‘¨æ³¢æ•°ã‚’æ¤œå‡º
    const spectral = this.analyzeSpectralContent(this.samples);
    const pitchResult = this.analyzePitch(this.samples, spectral);
    const frequency = pitchResult.frequency;
    const confidence = pitchResult.confidence;
    const observationProbs = pitchResult.observationProbs;
    
    // ä¿¡é ¼åº¦ã®è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    this.lastPitchConfidence = confidence;
    
    this.processDetectedFrequency(frequency, observationProbs, confidence);
  }

  private processDetectedFrequency(frequency: number, observationProbs?: Float32Array, confidence?: number): void {
    // PYIN ã®æ¤œå‡ºçµæœãŒä¿¡é ¼æ€§ãŒä½ã„å ´åˆã€spectral åˆ†æã‚’è£œå®Œã¨ã—ã¦ä½¿ç”¨
    if (frequency <= 0 || (confidence !== undefined && confidence < 0.4)) {
      const spectral = this.analyzeSpectralContent(this.samples);
      if (spectral.peaks.length > 0) {
        frequency = spectral.peaks[0].frequency;
        // ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æã®ä¿¡é ¼åº¦ã‚’è£œæ­£
        confidence = Math.min(0.7, spectral.clarity);
      } else {
        this.resetDetection();
        return;
      }
    }
    
    const currentTime = performance.now() / 1000;
    // ç„¡éŸ³æ™‚ã®èª¤æ¤œå‡ºã‚’é˜²ããŸã‚ã€è¨ˆæ¸¬ã•ã‚ŒãŸæœ€å¤§æŒ¯å¹…ãŒ silenceThreshold æœªæº€ãªã‚‰å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
    const currentMaxAmplitude = this.calculateMaxAmplitude(this.samples);
    if (currentMaxAmplitude < this.processingSettings.silenceThreshold) {
      this.resetDetection();
      return;
    }

    // PYIN ã¨ spectral ã‹ã‚‰å€™è£œã¨ãªã‚‹ãƒãƒ¼ãƒˆç•ªå·ã‚’å–å¾—
    const pyinCandidate = this.getClosestNote(frequency);
    const spectralData = this.analyzeSpectralContent(this.samples);
    const spectralCandidate = spectralData.peaks.length > 0
      ? this.getClosestNote(spectralData.peaks[0].frequency)
      : pyinCandidate;
    
    // ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„æƒ…å ±ã‚’ä½¿ç”¨
    let candidate: number;
    if (confidence !== undefined && confidence > 0.7) {
      // PYIN ã®ä¿¡é ¼åº¦ãŒé«˜ã„å ´åˆã¯ãã®çµæœã‚’å„ªå…ˆ
      candidate = pyinCandidate;
    } else {
      // ã‚¹ãƒšã‚¯ãƒˆãƒ«è§£æã¨ã®æ¯”è¼ƒã§æ±ºå®š
      candidate = Math.abs(frequency - this.noteFrequencies.get(pyinCandidate)!) < 
                 Math.abs(spectralData.peaks[0]?.frequency - this.noteFrequencies.get(spectralCandidate)!) 
                 ? pyinCandidate : spectralCandidate;
    }

    // HMM ã«ã‚ˆã‚‹å®‰å®šåŒ–å‡¦ç†
    if (observationProbs) {
      this.hmmProcessor.update(observationProbs);
      const hmmNote = this.hmmProcessor.getMostProbableNote();
      candidate = this.resolveNoteConflict(hmmNote, candidate);
    }

    // ãƒ”ãƒƒãƒå±¥æ­´ã«è¿½åŠ 
    this.updatePitchHistory(candidate, confidence || 0.5);

    // å®‰å®šã—ãŸãƒ”ãƒƒãƒã‚’å–å¾—
    const stableNote = this.getStableNote();
    if (stableNote !== -1) {
      this.handleDetectedPitch(this.noteFrequencies.get(stableNote)!);
    }
  }

  /**
   * æ¤œå‡ºã•ã‚ŒãŸãƒ”ãƒƒãƒã‚’å‡¦ç†
   */
  private handleDetectedPitch(frequency: number): void {
    if (this.isSeekingOrLooping()) {
      return;
    }

    const detectedNote = this.getClosestNote(frequency);
    const currentTime = performance.now() / 1000;

    // å‰å›ã¨åŒã˜ãƒãƒ¼ãƒˆã‹ãƒã‚§ãƒƒã‚¯
    if (detectedNote === this.lastDetectedNote) {
      this.consecutiveFrames++;
    } else {
      // æ–°ã—ã„ãƒãƒ¼ãƒˆã‚’æ¤œå‡º
      if (this.activeNote !== null && this.activeNote !== detectedNote) {
        // å‰ã®ãƒãƒ¼ãƒˆã‚’off
        this.onNoteOff(this.activeNote);
      }
      
      this.lastDetectedNote = detectedNote;
      this.consecutiveFrames = 1;
    }

    // é–¾å€¤ã‚’è¶…ãˆãŸã‚‰ãƒãƒ¼ãƒˆã‚ªãƒ³
    if (this.consecutiveFrames >= this.processingSettings.consecutiveFramesThreshold) {
      if (this.activeNote !== detectedNote) {
        // å‰ã®ãƒãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆã¯ãƒã‚¤ãƒ©ã‚¤ãƒˆè§£é™¤
        if (this.activeNote !== null && this.keyHighlightCallback) {
          this.keyHighlightCallback(this.activeNote, false);
        }
        
        this.activeNote = detectedNote;
        this.onNoteOn(detectedNote, 80); // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ™ãƒ­ã‚·ãƒ†ã‚£
        this.lastNoteOnTime = currentTime;
        
        // æ–°ã—ã„ãƒãƒ¼ãƒˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        if (this.keyHighlightCallback) {
          this.keyHighlightCallback(detectedNote, true);
        }
        
        // ã‚­ãƒ¼ãƒ—ãƒ¬ã‚¹ã‚¨ãƒ•ã‚§ã‚¯ãƒˆç™ºç«
        if (this.keyPressEffectCallback) {
          this.keyPressEffectCallback(detectedNote);
        }
      }
    }

    this.lastDetectedFrequency = frequency;
  }

  /**
   * ãƒ”ãƒƒãƒãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã®å‡¦ç†
   */
  private handleNoPitch(): void {
    this.consecutiveFrames = 0;
    
    const currentTime = performance.now() / 1000;
    
    // ä¸€å®šæ™‚é–“å¾Œã«ãƒãƒ¼ãƒˆã‚ªãƒ•
    if (this.activeNote !== null && (currentTime - this.lastNoteOnTime) > 0.1) {
      this.onNoteOff(this.activeNote);
      
      // ãƒã‚¤ãƒ©ã‚¤ãƒˆè§£é™¤
      if (this.keyHighlightCallback) {
        this.keyHighlightCallback(this.activeNote, false);
      }
      
      this.activeNote = null;
    }
    
    this.resetDetection();
  }

  /**
   * å‘¨æ³¢æ•°ã‹ã‚‰MIDIãƒãƒ¼ãƒˆç•ªå·ã‚’å–å¾—
   */
  private getClosestNote(frequency: number): number {
    if (frequency <= 0) return -1;
    
    // 12å¹³å‡å¾‹ã§MIDIãƒãƒ¼ãƒˆç•ªå·ã‚’è¨ˆç®—
    const noteNumber = Math.round(69 + 12 * Math.log2(frequency / 440));
    
    // æœ‰åŠ¹ç¯„å›²ï¼ˆA0-C8: 21-108ï¼‰å†…ã‹ãƒã‚§ãƒƒã‚¯
    if (noteNumber < 21 || noteNumber > 108) {
      return -1;
    }
    
    return noteNumber;
  }

  /**
   * æœ€å¤§æŒ¯å¹…ã‚’è¨ˆç®—
   */
  private calculateMaxAmplitude(samples: Float32Array): number {
    let maxAmplitude = 0;
    for (let i = 0; i < samples.length; i++) {
      maxAmplitude = Math.max(maxAmplitude, Math.abs(samples[i]));
    }
    return maxAmplitude;
  }

  /**
   * ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’æ›´æ–°
   */
  private updateNoteState(amplitude: number): void {
    if (amplitude > this.processingSettings.noteOnThreshold) {
      this.isNoteOn = true;
    } else if (amplitude < this.processingSettings.noteOffThreshold) {
      this.isNoteOn = false;
    }
  }

  /**
   * æ¤œå‡ºã‚’ãƒªã‚»ãƒƒãƒˆ
   */
  private resetDetection(): void {
    this.lastDetectedNote = -1;
    this.consecutiveFrames = 0;
    this.lastDetectedFrequency = 0;
  }

  /**
   * ã‚·ãƒ¼ã‚¯ã‚„ãƒ«ãƒ¼ãƒ—ä¸­ã‹ãƒã‚§ãƒƒã‚¯
   */
  private isSeekingOrLooping(): boolean {
    // gameInstanceã¸ã®å‚ç…§ãŒå¿…è¦ãªå ´åˆã¯å¤–éƒ¨ã‹ã‚‰æä¾›ã•ã‚Œã‚‹æƒ³å®š
    return false;
  }

  /**
   * ãƒ”ãƒƒãƒå±¥æ­´ã‚’æ›´æ–°
   */
  private updatePitchHistory(note: number, confidence: number): void {
    const timestamp = performance.now() / 1000;
    
    this.pitchHistory.push({
      note,
      confidence,
      timestamp
    });
    
    // å±¥æ­´ã‚µã‚¤ã‚ºã‚’åˆ¶é™
    if (this.pitchHistory.length > this.pitchHistorySize) {
      this.pitchHistory.shift();
    }
  }

  /**
   * å®‰å®šã—ãŸãƒ”ãƒƒãƒã‚’å–å¾—
   */
  private getStableNote(): number {
    if (this.pitchHistory.length < this.pitchHistorySize) {
      return -1;
    }

    // æœ€æ–°ã®å±¥æ­´ã‹ã‚‰æœ€ã‚‚å¤šãå‡ºç¾ã™ã‚‹ãƒãƒ¼ãƒˆã‚’å–å¾—
    const noteCounts = new Map<number, number>();
    let totalConfidence = 0;

    for (const history of this.pitchHistory) {
      const count = noteCounts.get(history.note) || 0;
      noteCounts.set(history.note, count + 1);
      totalConfidence += history.confidence;
    }

    // å¹³å‡ä¿¡é ¼åº¦ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹å ´åˆã¯å®‰å®šã—ã¦ã„ãªã„
    const avgConfidence = totalConfidence / this.pitchHistory.length;
    if (avgConfidence < 0.6) {
      return -1;
    }

    // æœ€ã‚‚å¤šãå‡ºç¾ã™ã‚‹ãƒãƒ¼ãƒˆã‚’è¿”ã™
    let maxCount = 0;
    let stableNote = -1;

    for (const [note, count] of noteCounts) {
      if (count > maxCount) {
        maxCount = count;
        stableNote = note;
      }
    }

    // éåŠæ•°ã‚’è¶…ãˆã‚‹å¿…è¦ãŒã‚ã‚‹
    return maxCount > this.pitchHistorySize / 2 ? stableNote : -1;
  }

  /**
   * HMMã¨ç¾åœ¨ã®å€™è£œã®ç«¶åˆã‚’è§£æ±º
   */
  private resolveNoteConflict(hmmNote: number, currentCandidate: number): number {
    // HMMã®ä¿¡é ¼åº¦ãŒé«˜ã„å ´åˆã¯HMMã‚’å„ªå…ˆ
    if (Math.abs(hmmNote - currentCandidate) <= 2) {
      return hmmNote;
    }
    
    // å¤§ããç•°ãªã‚‹å ´åˆã¯ç¾åœ¨ã®å€™è£œã‚’å„ªå…ˆ
    return currentCandidate;
  }

  /**
   * ã‚¹ãƒšã‚¯ãƒˆãƒ«åˆ†æ
   */
  private analyzeSpectralContent(samples: Float32Array): SpectralAnalysis {
    // FFTè¨ˆç®—
    const fftSize = Math.min(samples.length, 2048);
    const fftBuffer = new Float32Array(fftSize);
    fftBuffer.set(samples.subarray(0, fftSize));
    
    // ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ï¼ˆHanning windowï¼‰é©ç”¨
    for (let i = 0; i < fftSize; i++) {
      const window = 0.5 * (1 - Math.cos(2 * Math.PI * i / (fftSize - 1)));
      fftBuffer[i] *= window;
    }

    const magnitudes = this.computeFFTMagnitude(fftBuffer);
    const peaks = this.findSpectralPeaks(magnitudes);
    const centroid = this.calculateSpectralCentroid(peaks);
    const spread = this.calculateSpectralSpread(peaks, centroid);

    // ã‚¯ãƒ©ãƒªãƒ†ã‚£ï¼ˆæ˜ç­åº¦ï¼‰è¨ˆç®—
    const clarity = peaks.length > 0 ? peaks[0].magnitude / (magnitudes.reduce((a, b) => a + b, 0) / magnitudes.length) : 0;

    return {
      peaks,
      centroid,
      spread,
      clarity: Math.min(1.0, clarity)
    };
  }

  /**
   * PYIN ãƒ”ãƒƒãƒåˆ†æ
   */
  private analyzePitch(samples: Float32Array, spectral: SpectralAnalysis): PitchResult {
    if (!wasmMemory || !this.sampleRate) {
      return this.fallbackPitchDetection(samples, spectral);
    }

    try {
      // WASM ãƒ¡ãƒ¢ãƒªã«ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
      const ptr = alloc(samples.length * 4);
      const wasmBuffer = new Float32Array(wasmMemory.buffer, ptr, samples.length);
      wasmBuffer.set(samples);

      // WASM ãƒ”ãƒƒãƒåˆ†æå®Ÿè¡Œ
      const frequency = analyze_pitch(ptr, samples.length, this.sampleRate, this.processingSettings.pyinThreshold);
      
      // ãƒ¡ãƒ¢ãƒªè§£æ”¾
      free(ptr, samples.length * 4);

      const confidence = this.calculatePYINConfidence(samples, frequency);
      
      return {
        frequency,
        confidence,
        observationProbs: this.calculateObservationProbs(spectral.peaks)
      };
    } catch (error) {
      console.warn('WASM pitch analysis failed, using fallback:', error);
      return this.fallbackPitchDetection(samples, spectral);
    }
  }

  /**
   * ä½å‘¨æ³¢æ•°ç”¨ãƒ”ãƒƒãƒåˆ†æ
   */
  private analyzePitchLowFreq(samples: Float32Array, spectral: SpectralAnalysis): PitchResult {
    // ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒ•ã‚¡ã§ã‚ˆã‚Šç²¾å¯†ãªåˆ†æ
    const extendedSpectral = this.analyzeSpectralContent(samples);
    return this.analyzePitch(samples, extendedSpectral);
  }

  /**
   * ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ãƒ”ãƒƒãƒæ¤œå‡º
   */
  private fallbackPitchDetection(samples: Float32Array, spectral: SpectralAnalysis): PitchResult {
    if (spectral.peaks.length === 0) {
      return { frequency: 0, confidence: 0 };
    }

    // æœ€å¤§ãƒ”ãƒ¼ã‚¯ã‚’åŸºæº–ã¨ã™ã‚‹
    const dominantPeak = spectral.peaks[0];
    const confidence = Math.min(1.0, spectral.clarity * 0.8);

    return {
      frequency: dominantPeak.frequency,
      confidence,
      observationProbs: this.calculateObservationProbs(spectral.peaks)
    };
  }

  /**
   * è¦³æ¸¬ç¢ºç‡è¨ˆç®—
   */
  private calculateObservationProbs(peaks: SpectralPeak[]): Float32Array {
    const numStates = 88; // 88éµç›¤
    const probs = new Float32Array(numStates);
    
    for (const peak of peaks) {
      const noteIndex = this.getClosestNote(peak.frequency) - 21; // A0 = 21
      if (noteIndex >= 0 && noteIndex < numStates) {
        probs[noteIndex] += peak.magnitude;
      }
    }
    
    // æ­£è¦åŒ–
    const total = probs.reduce((a, b) => a + b, 0);
    if (total > 0) {
      for (let i = 0; i < numStates; i++) {
        probs[i] /= total;
      }
    }
    
    return probs;
  }

  /**
   * FFT magnitude è¨ˆç®—ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
   */
  private computeFFTMagnitude(samples: Float32Array): Float32Array {
    const N = samples.length;
    const magnitudes = new Float32Array(N / 2);
    
    // ç°¡æ˜“DFTå®Ÿè£…ï¼ˆå®Ÿéš›ã®æœ¬æ ¼å®Ÿè£…ã§ã¯é«˜é€ŸFFTã‚’ä½¿ç”¨ï¼‰
    for (let k = 0; k < N / 2; k++) {
      let real = 0;
      let imag = 0;
      
      for (let n = 0; n < N; n++) {
        const angle = -2 * Math.PI * k * n / N;
        real += samples[n] * Math.cos(angle);
        imag += samples[n] * Math.sin(angle);
      }
      
      magnitudes[k] = Math.sqrt(real * real + imag * imag);
    }
    
    return magnitudes;
  }

  /**
   * ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ”ãƒ¼ã‚¯æ¤œå‡º
   */
  private findSpectralPeaks(magnitudes: Float32Array): SpectralPeak[] {
    const peaks: SpectralPeak[] = [];
    const threshold = Math.max(...magnitudes) * 0.1; // æœ€å¤§å€¤ã®10%ä»¥ä¸Š
    
    for (let i = 1; i < magnitudes.length - 1; i++) {
      if (magnitudes[i] > magnitudes[i - 1] && 
          magnitudes[i] > magnitudes[i + 1] && 
          magnitudes[i] > threshold) {
        
        const frequency = (i * (this.sampleRate || 44100)) / (2 * magnitudes.length);
        peaks.push({
          frequency,
          magnitude: magnitudes[i],
          index: i
        });
      }
    }
    
    // magnitude ã§é™é †ã‚½ãƒ¼ãƒˆ
    peaks.sort((a, b) => b.magnitude - a.magnitude);
    
    // æœ€å¤§10å€‹ã®ãƒ”ãƒ¼ã‚¯ã¾ã§
    return peaks.slice(0, 10);
  }

  /**
   * ã‚¹ãƒšã‚¯ãƒˆãƒ«é‡å¿ƒè¨ˆç®—
   */
  private calculateSpectralCentroid(peaks: SpectralPeak[]): number {
    if (peaks.length === 0) return 0;
    
    let weightedSum = 0;
    let totalWeight = 0;
    
    for (const peak of peaks) {
      weightedSum += peak.frequency * peak.magnitude;
      totalWeight += peak.magnitude;
    }
    
    return totalWeight > 0 ? weightedSum / totalWeight : 0;
  }

  /**
   * ã‚¹ãƒšã‚¯ãƒˆãƒ«æ‹¡æ•£è¨ˆç®—
   */
  private calculateSpectralSpread(peaks: SpectralPeak[], centroid: number): number {
    if (peaks.length === 0) return 0;
    
    let weightedVariance = 0;
    let totalWeight = 0;
    
    for (const peak of peaks) {
      const deviation = peak.frequency - centroid;
      weightedVariance += deviation * deviation * peak.magnitude;
      totalWeight += peak.magnitude;
    }
    
    return totalWeight > 0 ? Math.sqrt(weightedVariance / totalWeight) : 0;
  }

  /**
   * PYINä¿¡é ¼åº¦è¨ˆç®—
   */
  private calculatePYINConfidence(samples: Float32Array, frequency: number): number {
    if (frequency <= 0) return 0;
    
    // ç°¡æ˜“ä¿¡é ¼åº¦è¨ˆç®—ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚ˆã‚Šè¤‡é›‘ãªè¨ˆç®—ï¼‰
    const amplitude = this.calculateMaxAmplitude(samples);
    const normalizedAmp = Math.min(1.0, amplitude / 0.5);
    
    // å‘¨æ³¢æ•°ãŒæœ‰åŠ¹ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
    const inRange = frequency >= this.processingSettings.minFrequency && 
                   frequency <= this.processingSettings.maxFrequency;
    
    return inRange ? normalizedAmp * 0.8 : 0;
  }

  /**
   * ãƒ‡ãƒã‚¤ã‚¹ãƒªã‚¹ãƒˆæ›´æ–°
   */
  public async updateDeviceList(): Promise<void> {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(device => device.kind === 'audioinput');
      
      // ãƒ‡ãƒã‚¤ã‚¹ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹æ›´æ–°
      document.querySelectorAll('.audio-devices').forEach(select => {
        const selectElement = select as HTMLSelectElement;
        selectElement.innerHTML = '<option value="">Select microphone...</option>';
        
        audioInputs.forEach(device => {
          const option = document.createElement('option');
          option.value = device.deviceId;
          option.textContent = device.label || `Microphone ${device.deviceId}`;
          selectElement.appendChild(option);
        });
      });
    } catch (error) {
      console.error('Failed to update device list:', error);
    }
  }

  /**
   * ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
   */
  private showError(message: string, selectId?: string): void {
    const targetSelector = selectId ? `#${selectId}` : '.audio-devices';
    const elements = document.querySelectorAll(targetSelector);
    
    elements.forEach(element => {
      let errorDiv = element.parentElement?.querySelector('.error-message');
      if (!errorDiv) {
        errorDiv = document.createElement('div');
        errorDiv.className = 'error-message text-red-500 text-sm mt-1';
        element.parentElement?.appendChild(errorDiv);
      }
      errorDiv.textContent = message;
      this.errorDisplays.set(element.id, errorDiv);
    });
  }

  /**
   * ã‚¨ãƒ©ãƒ¼éè¡¨ç¤º
   */
  private hideError(selectId?: string): void {
    const targetSelector = selectId ? `#${selectId}` : '.audio-devices';
    const elements = document.querySelectorAll(targetSelector);
    
    elements.forEach(element => {
      const errorDiv = element.parentElement?.querySelector('.error-message');
      if (errorDiv) {
        errorDiv.remove();
      }
      this.errorDisplays.delete(element.id);
    });
  }

  /**
   * æ¥ç¶šçŠ¶æ…‹å¤‰æ›´é€šçŸ¥
   */
  private notifyConnectionChange(connected: boolean): void {
    if (this.onConnectionChange) {
      this.onConnectionChange(connected);
    }
  }

  /**
   * å‡¦ç†ã®ä¸€æ™‚åœæ­¢ï¼ˆã‚·ãƒ¼ã‚¯æ™‚ãªã©ï¼‰
   */
  public pauseProcessingForSeek(): void {
    this.pauseProcessing = true;
    setTimeout(() => {
      this.pauseProcessing = false;
    }, 100);
  }

  /**
   * æ¥ç¶šçŠ¶æ…‹å–å¾—
   */
  public isConnected(): boolean {
    return this.mediaStream !== null && this.isProcessing;
  }

  /**
   * ç¾åœ¨ã®ãƒ‡ãƒã‚¤ã‚¹IDå–å¾—
   */
  public getCurrentDeviceId(): string | null {
    return this.currentDeviceId;
  }

  /**
   * ãƒªã‚¹ãƒ‹ãƒ³ã‚°é–‹å§‹
   */
  public startListening(): void {
    this.isProcessing = true;
    this.pauseProcessing = false;
    this.fadeInOutput();
  }

  /**
   * ãƒªã‚¹ãƒ‹ãƒ³ã‚°åœæ­¢
   */
  public stopListening(): void {
    this.isProcessing = false;
    this.fadeOutOutput();
    if (this.activeNote !== null) {
      this.onNoteOff(this.activeNote);
      
      // ãƒã‚¤ãƒ©ã‚¤ãƒˆè§£é™¤
      if (this.keyHighlightCallback) {
        this.keyHighlightCallback(this.activeNote, false);
      }
      
      this.activeNote = null;
    }
  }

  /**
   * ã‚­ãƒ¼ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šï¼ˆMIDIControllerçµ±åˆç”¨ï¼‰
   */
  public setKeyHighlightCallback(callback: (note: number, active: boolean) => void): void {
    this.keyHighlightCallback = callback;
  }

  /**
   * ã‚­ãƒ¼ãƒ—ãƒ¬ã‚¹ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šï¼ˆPIXIãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼çµ±åˆç”¨ï¼‰
   */
  public setKeyPressEffectCallback(callback: (note: number) => void): void {
    this.keyPressEffectCallback = callback;
  }

  /**
   * å‡¦ç†æœ‰åŠ¹çŠ¶æ…‹å–å¾—
   */
  public get enabled(): boolean {
    return this.isProcessing;
  }

  /**
   * å‡¦ç†æœ‰åŠ¹çŠ¶æ…‹è¨­å®š
   */
  public set enabled(value: boolean) {
    if (value) {
      this.startListening();
    } else {
      this.stopListening();
    }
  }

  /**
   * è¨­å®šæ›´æ–°
   */
  public updateConfig(config: any): void {
    // è¨­å®šã«å¿œã˜ã¦å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°
    if (config.minFrequency !== undefined) {
      this.processingSettings.minFrequency = config.minFrequency;
    }
    if (config.maxFrequency !== undefined) {
      this.processingSettings.maxFrequency = config.maxFrequency;
    }
    if (config.amplitudeThreshold !== undefined) {
      this.processingSettings.amplitudeThreshold = config.amplitudeThreshold;
    }
    if (config.pyinThreshold !== undefined) {
      this.processingSettings.pyinThreshold = config.pyinThreshold;
      console.log(`ğŸ¤ PYIN threshold updated to: ${config.pyinThreshold}`);
    }
  }

  /**
   * ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå…¥åŠ›è¨­å®šç”»é¢ç”¨ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
   */
  public setupAudioControls(): void {
    // ãƒ‡ãƒã‚¤ã‚¹ãƒªã‚¹ãƒˆæ›´æ–°ã¨ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼è¨­å®š
    this.updateDeviceList();
  }

  /**
   * åˆ‡æ–­å‡¦ç†
   */
  public async disconnect(): Promise<void> {
    this.isProcessing = false;
    
    // ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ¼ãƒˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’è§£é™¤
    if (this.activeNote !== null) {
      this.onNoteOff(this.activeNote);
      
      if (this.keyHighlightCallback) {
        this.keyHighlightCallback(this.activeNote, false);
      }
      
      this.activeNote = null;
    }
    
    // ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢
    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach(track => track.stop());
      this.mediaStream = null;
    }
    
    // AudioWorklet/ScriptProcessoråˆ‡æ–­
    if (this.workletNode) {
      this.workletNode.disconnect();
      this.workletNode = null;
    }
    
    if (this.scriptNode) {
      this.scriptNode.disconnect();
      this.scriptNode = null;
    }
    
    if (this.analyserTimer) {
      clearInterval(this.analyserTimer);
      this.analyserTimer = null;
    }
    
    // AudioContextçµ‚äº†ï¼ˆiOSä»¥å¤–ï¼‰
    if (this.audioContext && !this.isIOSDevice) {
      await this.audioContext.close();
      this.audioContext = null;
    }
    
    this.currentDeviceId = null;
    this.notifyConnectionChange(false);
  }

  private fadeInOutput(duration: number = 0.2): void {
    if (this.outputGainNode && this.audioContext) {
      const now = this.audioContext.currentTime;
      this.outputGainNode.gain.cancelScheduledValues(now);
      this.outputGainNode.gain.setValueAtTime(0, now);
      this.outputGainNode.gain.linearRampToValueAtTime(1, now + duration);
    }
  }

  private fadeOutOutput(duration: number = 0.1): void {
    if (this.outputGainNode && this.audioContext) {
      const now = this.audioContext.currentTime;
      this.outputGainNode.gain.cancelScheduledValues(now);
      this.outputGainNode.gain.setValueAtTime(this.outputGainNode.gain.value, now);
      this.outputGainNode.gain.linearRampToValueAtTime(0, now + duration);
    }
  }
} 